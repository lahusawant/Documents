dbutils.fs.ls('/FileStore/tables')
------------------------------------------------------------------------------------------------------
df_csv_1 = spark\
    .read\
        .format('csv')\
            .option('inferSchema',True)\
                .option('header', True)\
                    .load('/FileStore/tables/BigMart_Sales.csv')
df_1.display()
------------------------------------------------------------------------------------------------------
df_csv_2 = spark\
    .read\
        .csv('/FileStore/tables/BigMart_Sales.csv',inferSchema=True,header=True)
df_2.display()
------------------------------------------------------------------------------------------------------
df_json_1 = spark\
    .read\
        .format("json")\
            .option("inferSchema",True)\
                .option("header",True)\
                    .option("multiLine",False)\
                        .load("/FileStore/tables/drivers-1.json")
df_json_1.display()
------------------------------------------------------------------------------------------------------
df_schema_1.select(col("Item_Identifier")\
            .alias("Item_ID"))\
            .display()
------------------------------------------------------------------------------------------------------
df_json_1 = spark\
    .read\
        .format("json")\
            .option("inferSchema",True)\
                .option("header",True)\
                    .option("multiLine",False)\
                        .load("/FileStore/tables/drivers-1.json")
------------------------------------------------------------------------------------------------------
df_json_2 = spark\
    .read\
        .json("/FileStore/tables/drivers-1.json")
df_json_2.display()
------------------------------------------------------------------------------------------------------
df_schema_1 = spark\
                    .read\
                        .format("csv")\
                            .schema(ddl_schema)\
                                .option("header",True)\
                                    .load("/FileStore/tables/BigMart_Sales.csv")
df_schema_1.display()
df_schema_1.printSchema()
------------------------------------------------------------------------------------------------------
from pyspark.sql.types import *
from pyspark.sql.functions import *
struct_schema = StructType([
                            StructField('Item_Identifier',StringType(),True),
                            StructField('Item_Weight',StringType(),True),
                            StructField('Item_Fat_Content',StringType(),True),
                            StructField('Item_Visibility',StringType(),True),
                            StructField('Item_Type',StringType(),True),
                            StructField('Item_MRP',StringType(),True),
                            StructField('Outlet_Identifier',StringType(),True),
                            StructField('Outlet_Establishment_Year',StringType(),True),
                            StructField('Outlet_Size',StringType(),True),
                            StructField('Outlet_Location_Type',StringType(),True),
                            StructField('Outlet_Type',StringType(),True),
                            StructField('Item_Outlet_Sales',StringType(),True)
                        ])
df_schema_2 = spark\
                    .read\
                        .format("csv")\
                            .option("header",True)\
                                .load("/FileStore/tables/BigMart_Sales.csv")
df_schema_2.display()
df_schema_2.printSchema()
------------------------------------------------------------------------------------------------------
df_schema_1.select("Item_Identifier",\
                    "Item_Weight",\
                    "Item_Fat_Content")\
            .display()
------------------------------------------------------------------------------------------------------
df_schema_1.select(col("Item_Identifier"),\
                    col("Item_Weight"),\
                    col("Item_Fat_Content"))\
            .display()
------------------------------------------------------------------------------------------------------
df_schema_1.select(col("Item_Identifier")\
            .alias("Item_ID"))\
            .display()
------------------------------------------------------------------------------------------------------
df_schema_1.filter(col("Item_Fat_Content")=="Regular")\
            .display()

df_schema_1.filter(\
                    (col("Item_Type") == "Soft Drinks")\
                    & (col("Item_Weight") < 10))\
            .display()

df_schema_1.filter(\
                (col("Outlet_Location_Type").isin("Tier 1","Tier 2"))\
                 & (col("Outlet_Size").isNull()))\
            .display()
df_schema_1.select(col("Item_Identifier")\
            .alias("Item_ID"))\
            .display()
------------------------------------------------------------------------------------------------------
df_schema_1.withColumnRenamed("Item_Weight","Item_WT")\
            .display()
------------------------------------------------------------------------------------------------------
df_schema_1.withColumn("flag",lit("new")).display()

df_schema_1.withColumn("Multiple",col("Item_weight")*col("Item_MRP")).display()

df_schema_1.withColumn("Item_Fat_Content",regexp_replace(col("Item_Fat_Content"),"Regular","Reg"))\
            .withColumn("Item_Fat_Content",regexp_replace(col("Item_Fat_Content"),"Low Fat","LF"))\
            .display()
